{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wUL_Fy5qUDI"
   },
   "source": [
    "# Project Three: Image Classification with ConvNets\n",
    "\n",
    "The project here is design to teach you the basics of deep neural networks.  \n",
    "You will design a ConvNet (also call a CNN or Convolution Neural Network) to ingest images and  \n",
    "classify the dominant object in the image. The objective here is to get accustomed to programming  \n",
    "with PyTorch (or Keras), and learn the workflow for training neural networks. In addition to training  \n",
    "from scratch, to will also learn to load pretrained models that are then finetuned on your dataset (transfer learning).  \n",
    "\n",
    "\n",
    "We will work through a series of steps:\n",
    "1. Acquire, Load, and Explore the Data\n",
    "2. Prepare the Data for your ConvNet\n",
    "3. Select and Prepare your ConvNet Model\n",
    "4. Utilize transfer learning, finetuning, and training from scratch.\n",
    "5. Evaluate and reiterate to improve your ConvNet.\n",
    "\n",
    "Similar to the previous projects, we will consolidate this notebook into four following task:\n",
    "\n",
    "* Task 1 is dedicated to EDA on the image dataset.\n",
    "* Task 2 prepares the data into the correct format and instantiates your ConvNet (+ with pretrained weights if doing EC).\n",
    "* Task 3 is building an accurate ConvNet. Train your own model. You can use an off-the-self model with finetuning as 20% EC.\n",
    "* Task 4 completes the testing, and analysis. Is the model accurate on the testset? How can it be improved? Show what changes you did to improve (batch size, learning rate, etc).\n",
    "\n",
    "For this project, the data is provided in a zip file attached into the Canvas page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeYRnesWqvLm"
   },
   "source": [
    "### Task 1: Exploratory Data Analysis (10%)\n",
    "\n",
    "There are a few steps to this task. These involve an unzip operation, then traversal into the directory for statistics.  \n",
    "A comprehensive check of the data involves the image dimensions, number of images, number of image classes.  \n",
    "Organize your results into a readable format and also provide previews of a subset of the images.  \n",
    "In addition to the above, commute the mean & std for the pixel values in the dataset (across all images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#EDA goes here\n",
    "#Oliver James, branch 1 test comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnPfmHAOteOI"
   },
   "source": [
    "### Task 2a: Prepare the Data (10%)\n",
    "There are two critical steps that need to done here.  \n",
    "First, you need to create a list of file paths (to the actual files). Then you randomize/shuffle the list.  \n",
    "The list now holds the paths to all your data. Use the following splits: trainset is 90%, validset is 5%, and testset is 5%.  \n",
    "Second, explore some data augmentation techniques with torch.transform.  \n",
    "\n",
    "Documentation on transforms:  \n",
    "[https://pytorch.org/vision/0.13/transforms.html](https://pytorch.org/vision/0.13/transforms.html)  \n",
    "[https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py](https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py)   \n",
    "Documentation for DataLoader: [https://pyimagesearch.com/2021/10/04/image-data-loaders-in-pytorch/](https://pyimagesearch.com/2021/10/04/image-data-loaders-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#code to get you started on transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import RandomCrop\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "\n",
    "#put your calculated std and mean below\n",
    "std  = 0\n",
    "mean = 0\n",
    "transform = Compose([ToTensor(),\n",
    "                     #additional transforms such as RandomCrop\n",
    "                     #optionally resize images to ensure consistent input dimensions\n",
    "                    Normalize(std=std,mean=mean)])\n",
    "#print out tensors to verify correct transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#code to get you started on dataloading\n",
    "import os\n",
    "import path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get class names (folder names)\n",
    "        self.classes = sorted(entry.name for entry in os.scandir(root_dir) if entry.is_dir())\n",
    "        \n",
    "        # Create class to index mapping\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Collect all image paths and their labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_data_splits(root_dir,\n",
    "                       transforms,\n",
    "                       train_ratio=0.7,\n",
    "                       val_ratio=0.15,\n",
    "                       test_ratio=0.15,\n",
    "                       random_seed=42):\n",
    "    \"\"\"\n",
    "    Create train, validation, and test splits for the dataset\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): Path to the root directory containing image folders\n",
    "        train_ratio (float): Proportion of data for training\n",
    "        val_ratio (float): Proportion of data for validation\n",
    "        test_ratio (float): Proportion of data for testing\n",
    "        random_seed (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_dataset, val_dataset, test_dataset)\n",
    "    \"\"\"\n",
    "    #ensure ratios sum to 1\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1\"\n",
    "    \n",
    "    # Create the full dataset\n",
    "    full_dataset = CustomImageDataset(root_dir, transform=transform)\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(random_seed)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size   = int(total_size * val_ratio)\n",
    "    test_size  = total_size - train_size - val_size\n",
    "    \n",
    "    # Create splits\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(random_seed)\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#create three dataloaders, one each for the train, valid, and test sets\n",
    "#print the sizes for each dataset, and ensure they sum to the total dataset size\n",
    "from tabulate import tabulate\n",
    "\n",
    "#set to your actual data directory\n",
    "data_dir = '/path/to/your/image/folders'\n",
    "    \n",
    "#create data splits (hint: see above functions)\n",
    "\n",
    "#create dataloaders, experiment with batchsize\n",
    "\n",
    "#print dataset sizes\n",
    "print(\"Dataset Sizes\")\n",
    "print(\"-------------\")\n",
    "table = [['train', 'valid', 'test', 'total'], [0,0,0,0]]\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b: Instantiate the Model (20%)\n",
    "The sequence of layers and their composition has a tremendous effect on the testset accuracy.  \n",
    "When you find your model not 'working', it is a good idea to revisit this task.  \n",
    "Building a ConvNet is simple with PyTorch. There are only two functions, the **\\_\\_init\\_\\_()** and **forward()**.  \n",
    "**\\_\\_init\\_\\_()** inherits its functionality from the nn.Module and is used to enumerate the layers and their properties.  \n",
    "**forward()** defines how the layers ingest input (the raw pixels) between the layers leading up to the output.  \n",
    "For more documentation: [https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html](https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html)  \n",
    "To get you started, use the template below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class Example(nn.Module):\n",
    "    def __init__(self,\n",
    "                 inf,\n",
    "                 outf,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 bias=False,\n",
    "                ):\n",
    "        #initializes the class with PyTorch's neural network utilities\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        #BatchNorm is a type of normalization applied across a batch of samples.\n",
    "        #this means, if 32 images are processed concurrently, their statistics are\n",
    "        #used for the ConvLayer output normalization. Improves final accuracy.\n",
    "        self.norm_layer = nn.BatchNorm2d\n",
    "        #ReLU is the activation applied to the ConvLayer output\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        #define convolutional layers below (you should experiment here).\n",
    "        self.conv1 = nn.Conv2d(inf, outf, kernel_size=3,\n",
    "                               padding=1, stride=stride, bias=bias)\n",
    "        self.norm1 = self.norm_layer(outf)\n",
    "        self.conv2 = nn.Conv2d(outf,outf, kernel_size=3,\n",
    "                               padding=1, stride=1, bias=bias)\n",
    "        self.norm2 = self.norm_layer(outf)\n",
    "\n",
    "        #define one or more linear layers. the last layers output must match the number of classes.\n",
    "        #self.fc1 = nn.Linear()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y  = self.conv1(X)\n",
    "        Y  = self.norm1(Y)\n",
    "        Y  = self.activation(Y)\n",
    "\n",
    "        Y  = self.conv2(Y)\n",
    "        Y  = self.norm2(Y)\n",
    "\n",
    "        Y = self.activation(Y)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a: Selecting Hyperparameters (10%)\n",
    "\n",
    "The hyperparameters can make or break your model (regardless of how good the architecuture is).  \n",
    "Take your time to thoughtfully select an optimizer, loss function, learning rate, and train epochs.  \n",
    "For more details on **Task 3** as whole, read the documentation at [https://pytorch.org/tutorials/beginner/introyt/trainingyt.html](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9apbZGptej6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b: Model Training and Validation (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# type a function here that trains for one epoch\n",
    "def train(insert_parameters_here):\n",
    "    #turn on training model; enables gradient calculations.\n",
    "    model.train()\n",
    "\n",
    "    #your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# type a function here that loops over the validation set\n",
    "@torch.inference_mode()\n",
    "def validation(insert_parameters_here):\n",
    "    #turn off training model; disables gradient calculations.\n",
    "    model.eval()\n",
    "\n",
    "    #your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3c: Testset Evaluation (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# calculate the accuracy for your model.\n",
    "# note: the testset should only be used here.\n",
    "# type a function here that loops over the validation set\n",
    "@torch.inference_mode()\n",
    "def test(insert_parameters_here):\n",
    "    #turn off training model; disables gradient calculations.\n",
    "    model.eval()\n",
    "\n",
    "    #your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWeSMqVLHfk2"
   },
   "source": [
    "### Task 4: Analysis and Evaluation (10%)\n",
    "\n",
    "\n",
    "1. An introduction to the dataset, what did your EDA reveal?\n",
    "2. If your EDA helped you build a better model, briefly type about.\n",
    "3. What kind of distribution is the data? Are the images of similar classes?\n",
    "4. Explain how you built your model. What type of layers, how many, and why.\n",
    "5. Discuss pain points and how you iterated towards a better model.\n",
    "\n",
    "The points above are for guidance; you can choose your template and structure.  \n",
    "The idea is to present a short report (no word counts) that is structured, clear, and concise.  \n",
    "You can refer back to your figures and use external links to explain your insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit: Use a Pretrained Model (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# extra credit code goes here. PyTorch has many pretrained models on the web and also from torch hub.\n",
    "# you will need to retrain the final layer(s) but should leave most of the model frozen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJSFgNBQrhQU"
   },
   "source": [
    "### Submission:\n",
    "\n",
    "You need to prepare your ipynb/jupyter notebook for grading.\n",
    "The two main tasks are ensuring all your cell outputs are present and that you convert the notebook to PDF.\n",
    "\n",
    "The instructs will vary slightly based on the platform (collab, kaggle, anaconda, etc).\n",
    "Generally, inside the notebook, you will want to:\n",
    "1. Restart & clear all cell outputs (optional, may detect buggy program control flow)\n",
    "2. Run all (must do; I need to see your code cell outputs!)\n",
    "\n",
    "Next, you need to download the notebook as a PDF. Exporting as PDF is a bit tricky but the steps below should work:\n",
    "1. Download the notebook. (all platforms allow the default .ipynb export)\n",
    "2. https://onlineconvertfree.com/convert-format/ipynb-to-pdf/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lGvLE9H6ptL"
   },
   "source": [
    "### Rubric:\n",
    "\n",
    "Complete all tasks above and see their associated percentage allocations.  \n",
    "In general, ensure your code runs correctly.  Make sure the submitted PDF includes your code outputs.  \n",
    "\n",
    "You will be given significant credit for documentation and pseudo-code.\n",
    "For more details, please read the rubric PDF in the assignment files.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Assignment5_abc123.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
